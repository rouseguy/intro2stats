{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Why use linear regression?\n",
    "\n",
    "1. Easy to use\n",
    "2. Easy to interpret\n",
    "3. Basis for many methods\n",
    "4. Runs fast\n",
    "5. Most people have heard about it :-) \n",
    "\n",
    "### Libraries in Python for Linear Regression\n",
    "\n",
    "The two most popular ones are\n",
    "\n",
    "1. `scikit-learn`\n",
    "2. `statsmodels`\n",
    "\n",
    "We highly recommend learning `scikit-learn` since that's also the machine learning package in Python.\n",
    "\n",
    "## Problem\n",
    "\n",
    "Could we predict price of weed in a state using the demographic information? \n",
    "\n",
    "For this session, let's do this. For January 2015, let's find average price for high quality weed across all the states. Let's assume that we don't know what the prices are for the following states: \n",
    "<br>\n",
    "iowa, kentucky, missouri, nevada, wyoming, south dakota, new jersey, michigan, idaho\n",
    "<br>\n",
    "\n",
    "Those are our **test** set. The remaining states are our **train** set. We need to train the model on the train dataset and predict for the test dataset. \n",
    "\n",
    "Since we also know the actual mean prices for the test states, let's verify how good our models are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "weed_pd = pd.read_csv(\"../data/Weed_Price.csv\", parse_dates=[-1])\n",
    "demo_pd = pd.read_csv(\"../data/Demographics_State.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weed_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weed_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_pd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, weed price dataset has states' first alphabet capitalized. \n",
    "The below command will convert it to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str.lower(\"Alabama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?weed_pd.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weed_pd.State = weed_pd[\"State\"].apply(lambda x: str.lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weed_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.unique(weed_pd.State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.unique(demo_pd.region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's get month and year of the date, so that we can select only Jan 2015 data\n",
    "weed_pd[\"Month\"] = weed_pd[\"date\"].apply(lambda x: x.month)\n",
    "weed_pd[\"Year\"] = weed_pd[\"date\"].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weed_jan2015_pd = weed_pd.ix[(weed_pd.Year==2015) & (weed_pd.Month==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weed_jan2015_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weed_jan2015_summarized = weed_jan2015_pd[[\"State\", \"HighQ\"]].groupby(\"State\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The source price dataset for our model \n",
    "weed_jan2015_summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_states = [\"iowa\", \"kentucky\", \"missouri\", \"nevada\", \"wyoming\", \\\n",
    "               \"south dakota\", \"new jersey\", \"michigan\", \"idaho\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_for_model = pd.merge(weed_jan2015_summarized, demo_pd, left_on=\"State\", right_on=\"region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_for_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, creating train and test dataset\n",
    "criterion = weed_jan2015_summarized[\"State\"].map(lambda x: x in test_states)\n",
    "#Another way to do it\n",
    "#criterion = weed_jan2015_summarized.State.isin(test_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Train data labels: \\n\", ~criterion, \"\\n\\n\", \"Test data labels: \\n\", criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data_for_model[~criterion]\n",
    "test = data_for_model[criterion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression \n",
    "\n",
    "Let's use `statsmodels` for this workshop. \n",
    "\n",
    "Linear regression is of the form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "\n",
    "- $y$ is what we have the predict/independent variable/response variable\n",
    "- $\\beta_0$ is the intercept/slope\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature/dependent variable)\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature/dependent variable)\n",
    "\n",
    "The $\\beta$ are called *model coefficients*\n",
    "\n",
    "The model coefficients are estimated in this process. (In Machine Learning parlance - the weights are learned using the algorithm). The objective function is least squares method. \n",
    "<br>\n",
    "\n",
    "**Least Squares Method** : To identify the weights so that the overall solution minimizes the sum of the squares of the errors made in the results of every single equation. [Wiki](https://en.wikipedia.org/wiki/Least_squares)\n",
    "\n",
    "![Estimating coefficients](img/leastsquare.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "sns.set(color_codes = True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First step: Let's visualize bivariate plots with  a trend line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x=\"percent_white\", y = \"HighQ\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x=\"total_population\", y=\"HighQ\", data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Plot for `HighQ` vs `per_capita_income` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting another kind of plot/model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?sns.lmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"total_population\", y=\"HighQ\", data=train, order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#More plots.\n",
    "\n",
    "#Visualizing correlation matrix using a heatmap\n",
    "\n",
    "sns.heatmap(train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?sns.pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Multiple scatter plot\n",
    "\n",
    "sns.pairplot(train, x_vars='HighQ', y_vars=['total_population', 'percent_white', 'percent_black', \\\n",
    "                                           'per_capita_income', 'median_rent', 'median_age'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, let's build a single variable model.**\n",
    "\n",
    "Let's try to estimate price as a function of population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [\"total_population\"]\n",
    "train_x = train[feature_columns]\n",
    "train_y = train['HighQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1 = LinearRegression()\n",
    "model_1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print model_1.intercept_\n",
    "print model_1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's use the model for prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1_predict = model_1.predict(test[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1_predict = pd.DataFrame({'States': test.State, 'Actual Price': test.HighQ, 'Predicted Price': model_1_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing mean squared error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Root Mean square error on test dataset\n",
    "np.sqrt(np.mean(np.square(model_1_predict['Actual Price'] - \\\n",
    "                         model_1_predict['Predicted Price'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lower the RMSE, better the model **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Create model using `total_population` and `per_capita_income` as the features. Report RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointers\n",
    "\n",
    "To build the model the right way, the following need to be done. They are left as exercise. \n",
    "\n",
    "1. Scale the features\n",
    "2. Use cross-validation\n",
    "3. As more features are added, the model becomes complicated and would overfit the data. Will need regularization\n",
    "4. Try feature transformation to see if lower RMSE is possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why wasn't **R-square** and **p-value** covered? \n",
    "\n",
    "- Linear models rely upon a lot of assumptions ([here](http://andrewgelman.com/2013/08/04/19470/)). If assumptions are violated, the diagnostics obtained from the model cannot be relied. \n",
    "- Biggest challenge is that adding any feature will increase the R-square. One way to counter this is to use adjusted R-squre.\n",
    "- Take a step back and think - why do we need to report those numbers? We want some estimate of generalization. Cross-validation score provides a general framework for reporting generalization. And this will hold good across all models. And thus, multiple models can be compared. This is the machine learning approach and is widely used in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
